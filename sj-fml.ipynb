{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd08f0e6e8876776058453f48ad7c7dcdebdb8994a74dd96d3c38b5ba45b7b9008d",
   "display_name": "Python 3.9.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from the CSV file to a pandas DataFrame.\n",
    "\n",
    "player_df = pd.read_csv('player_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the first five rows of the player_df DataFrame.\n",
    "player_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total up the number of NaN values in each row of the DataFrame.\n",
    "player_df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total up the number of NaN values in each row of the DataFrame.\n",
    "player_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out the information about the Dataframe\n",
    "player_df.info()"
   ]
  },
  {
   "source": [
    "Drop columns\n",
    "To drop columns, you'll use the dropna() method. Like isna(), dropna() looks for NaN values. But it goes a step further and removes either the rows or the columns that contain NaN values. Start by setting some parameters to the method:\n",
    "\n",
    "By default, dropna() removes rows, so specify that you want to remove columns by using the axis parameter.\n",
    "The dropna() method usually returns a new DataFrame. Use the inplace parameter to tell it to drop these columns in the original player_df DataFrame.\n",
    "You also want dropna() to remove only columns in which all of the values are missing. So set the how parameter to 'all'."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns that have no values\n",
    "#putting the axxis=columns will remove columns\n",
    "player_df.dropna(axis='columns', inplace=True, how='all')\n",
    "player_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df.info()"
   ]
  },
  {
   "source": [
    "Drop rows\n",
    "You should also address the possibility that an entire row is missing values. That is, one of the players in the DataFrame might have no stats. You can try to address this missing row as you did last time, by using dropna(). But this time, use the method's default row-based behavior."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that have no values.\n",
    "player_df.dropna(inplace=True, how='all')\n",
    "player_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the entire DataFrame.\n",
    "player_df"
   ]
  },
  {
   "source": [
    "Now you see that three rows are missing the same three values. Another row is missing 10 values. This information indicates two things:\n",
    "\n",
    "The dataset likely comes from two datasets that were joined together, and both of these earlier datasets had missing rows.\n",
    "You'll need to use critical thinking to determine how to remove these rows.\n",
    "The dataset is small enough that you could manually drop the problem rows. But that shortcut wouldn't give you practice dealing with larger datasets, where manual removal isn't practical. So use the built-in pandas methods instead.\n",
    "\n",
    "The how parameter in dropna() can be set to only 'any' or 'all'. Neither of those settings will get you what you need. Instead, use the thresh parameter.\n",
    "\n",
    "The thresh parameter refers to threshold. This parameter lets you set the minimum number of non-NaN values a row or column needs to avoid being dropped by dropna(). To remove specific rows from the DataFrame, set thresh to 12."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows that don't have at least 12 non-NaN values.\n",
    "player_df.dropna(inplace=True, thresh=12)\n",
    "player_df.isna().sum()"
   ]
  },
  {
   "source": [
    "Because you've dropped rows, the index in the DataFrame is compromised. You see this problem if you print out the first 10 rows of the DataFrame:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 10 rows of the player_df DataFrame.\n",
    "player_df.head(10)"
   ]
  },
  {
   "source": [
    "You see that the index counts 0 through 10, skipping 8. The row that had the index of 8 was dropped because it had more than two NaN values. In the 14 columns, the rows that had three or more NaN values didn't meet the threshold of 12 you set when you dropped rows earlier.\n",
    "\n",
    "To fix this problem, reset the index for the DataFrame. This fix saves you from problems down the road when you're working with the DataFrame. While you're at it, take a look at the now smaller DataFrame."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renumber the DataFrame index to account for the dropped rows.\n",
    "player_df.reset_index(drop=True, inplace=True)\n",
    "player_df.info()"
   ]
  },
  {
   "source": [
    "Check for outliers\n",
    "\n",
    "Outliers are data values so far outside the distribution of other values that they bring into question whether they even belong in the dataset. Outliers often arise from data errors or other undesirable noise. You'll always need to check for and deal with possible outliers before you analyze the data.\n",
    "\n",
    "A quick way to identify outliers is to use the pandas describe() function:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df.describe()"
   ]
  },
  {
   "source": [
    "Here you see, for example, that the mean for all 42 players is 1592.38 points. But look at the numbers for min (183), 25% (1390.75), 50% (1680.0), 75% (1826.25), and max (2062). Here, the min points (183) might be an outlier. You can use box plots to visualize the values and determine possible outliers.\n",
    "\n",
    "Create box plots for columns\n",
    "\n",
    "The traditional tool for probing for outlying data values is the box plot. The box in box plot refers to a box drawn around the range of data from the 25th percentile to the 75th percentile. (These percentiles demarcate important quarters of the data. Their range is called the interquartile range.) This box is the middle 50% of the data values for a given variable (a column in a DataFrame). You use another line to mark the median of the data, which is the 50th percentile.\n",
    "\n",
    "The box plot is also called a box-and-whisker plot because you draw a T shape above and below the box to encompass the maximum and minimum values of the data, excluding outliers. This last part is important for your purposes because it lets you graphically identify outliers.\n",
    "\n",
    "Ideally, you would produce the box plots for your columns in a single matrix that you can easily scan. Unfortunately, no single function produces multiple box plots, so you'll write a for loop instead.\n",
    "\n",
    "Because of how the Seaborn library in Python works, you need to explicitly state the cell in the matrix where you want to render each box plot. Use the Python floor-division operator (//) to divide the 13 columns of interest (you don't need to look at ID) into rows. Use the modulo operator (%) to derive the column.\n",
    "\n",
    "First, import the Matplotlib and Seaborn libraries into your notebook:\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#python -m pip install -U pip\n",
    "\n",
    "#python -m pip install -U matplotlib\n",
    "\n",
    "#pip install seaborn\n",
    "\n",
    "#python -m pip install seaborn\n",
    "\n",
    "In some cases, an installation of seaborn will appear to succeed, but trying to import it will raise an error with the message \"No module named seaborn\". This usually means that you have multiple Python installations on your system and that your pip or conda points towards a different installation than where your interpreter lives. Resolving this issue will involve sorting out the paths on your system, but it can sometimes be avoided by invoking pip with python -m pip install seaborn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "source": [
    "Now you can:\n",
    "\n",
    "Create a list of the column names, excluding ID. Use the list to find specific values within each row.\n",
    "\n",
    "Create a matrix of subplots so you have one figure that shows all 13 columns.\n",
    "\n",
    "Add padding around the subplots to make them easier to read. \n",
    "\n",
    "Create a box plot based on the data in each column, across all of the rows."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all column names, except for ID.\n",
    "cols = list(player_df.iloc[:, 1:])\n",
    "\n",
    "fig = plt.figure(figsize=(18, 11))\n",
    "fig.tight_layout(pad=5.0)\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.hist(player_df[cols[i]], bins=30)\n",
    "    plt.title(cols[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(player_df.iloc[:, 1:])\n",
    "\n",
    "#print(cols)\n",
    "###['points', 'possessions', 'team_pace', 'GP', 'MPG', 'TS%', 'AST', 'TO', 'USG', 'ORR', 'DRR', 'REBR', 'PER']\n",
    "\n",
    "# Create a 3x5 matrix of subplots.\n",
    "#fig and axes are variables that can be change\n",
    "#3, 5 = 3 rows 5 columns of boxes\n",
    "#figsize = size of each graph area\n",
    "fig, axes = plt.subplots(3, 5, figsize=(18, 11))\n",
    "#fmlfig, fmlaxes = plt.subplots(3, 3, figsize=(20, 13))\n",
    "\n",
    "# Create padding around subplots to make the axis labels readable.\n",
    "#spaces between each graph\n",
    "fig.tight_layout(pad=5.0)\n",
    "#fmlfig.tight_layout(pad=5.0)\n",
    "\n",
    "\n",
    "#sns.boxplot((ax=fmlaxes[0, 0], y=player_df[cols[0]]))\n",
    "# Loop over the columns of the DataFrame and create a box plot for each one.\n",
    "for i in range(len(cols)):\n",
    "    sns.boxplot(ax=axes[i//5, i%5], y=player_df[cols[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from plotnine import *\n",
    "\n",
    "(ggplot(player_df)         # defining what data to use\n",
    " + aes(x='points', y='possessions', color='ID', size='ID', fill='ID', alpha='ID')    # defining what variable to use\n",
    " + geom_point() # defining the type of plot to use\n",
    " #+ facet_wrap(['ID'])\n",
    " + theme(axis_text_x = element_text(angle=90, size=6))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the index number of the row that has the lowest value in 'points'.\n",
    "# Identify OUTLIERS\n",
    "# you can use the idxmin() method on both columns\n",
    "\n",
    "points_outlier = player_df['points'].idxmin()\n",
    "points_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the index number of the row that has the lowest value in 'possession'.\n",
    "possession_outlier = player_df['possessions'].idxmin()\n",
    "possession_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the row that has the outlying values for 'points' and 'possessions'.\n",
    "player_df.drop(player_df.index[points_outlier], inplace=True)\n",
    "\n",
    "# Check the end of the DataFrame to ensure that the correct row was dropped.\n",
    "player_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index after dropping outliers\n",
    "player_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run another scatter plot after dropping outliers\n",
    "\n",
    "(ggplot(player_df)         # defining what data to use\n",
    " + aes(x='points', y='possessions', color='ID', size='ID', fill='ID', alpha='ID')    # defining what variable to use\n",
    " + geom_point() # defining the type of plot to use\n",
    " #+ facet_wrap(['ID'])\n",
    " + theme(axis_text_x = element_text(angle=90, size=6))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all column names, except for 'ID'.\n",
    "cols = list(player_df.iloc[:, 1:])\n",
    "\n",
    "# Define the size for the plots and add padding around them.\n",
    "fig = plt.figure(figsize=(18, 11))\n",
    "fig.tight_layout(pad=5.0)\n",
    "\n",
    "# Loop over the columns in the DataFrame and create a histogram for each one.\n",
    "for i in range(len(cols)):\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.hist(player_df[cols[i]], bins=30)\n",
    "    plt.title(cols[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram for the 'GP' column.\n",
    "plt.hist(player_df['GP'], bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram for the 'GP' column, this time as a probability density.\n",
    "plt.hist(player_df['GP'], density=True, bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the KDE for 'GP' over the probability-density histogram.\n",
    "plt.hist(player_df['GP'], density=True, bins=15)\n",
    "plt.title('GP histogram')\n",
    "sns.kdeplot(player_df['GP']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the KDE for 'GP' over the probability-density histogram.\n",
    "plt.hist(player_df['PER'], density=True, bins=15)\n",
    "plt.title('PER histogram')\n",
    "sns.kdeplot(player_df['PER']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all column names, except for 'ID'.\n",
    "cols = list(player_df.iloc[:, 1:])\n",
    "\n",
    "# Create a 3x5 matrix of subplots and add padding around them for readability.\n",
    "fig, axes = plt.subplots(3, 5, figsize=(18, 11))\n",
    "fig.tight_layout(pad=4.0)\n",
    "\n",
    "# Loop over the columns of the DataFrame and create a KDE for each one.\n",
    "for i in range(len(cols)):\n",
    "    sns.kdeplot(ax=axes[i//5, i%5], data=player_df[cols[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the KDE for 'points' over the probability-density histogram.\n",
    "plt.hist(player_df['points'], density=True, bins=15)\n",
    "plt.title('Points histogram')\n",
    "sns.kdeplot(player_df['points']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the rows where players scored more than 1,600 points:\n",
    "player_df.loc[player_df['points'] >= 1600].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the KDE for 'DRR' over the probability-density histogram.\n",
    "plt.hist(player_df['DRR'], density=True, bins=15)\n",
    "plt.title('DRR histogram')\n",
    "sns.kdeplot(player_df['DRR']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df.loc[(player_df['points'] >= 1600) & (player_df['DRR'] >= 15)].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the KDE for 'PER' over the probability-density histogram.\n",
    "plt.hist(player_df['PER'], density=True, bins=15)\n",
    "plt.title('PER histogram')\n",
    "sns.kdeplot(player_df['PER']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df.loc[(player_df['points'] >= 1600) & (player_df['DRR'] >= 15) & (player_df['PER'] >= 17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df.loc[player_df['ID'] == 34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the list to house the player data.\n",
    "pop_list = []\n",
    "\n",
    "# If the ID number is 30 or less, it's a human player; otherwise, it's a Tune Squad player.\n",
    "for id in player_df['ID']:\n",
    "    if id <= 30:\n",
    "        pop_list.append('player'+str(id))\n",
    "    else:\n",
    "        pop_list.append('tune_squad'+str(id%30))\n",
    "\n",
    "pop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign this list as the values for the new player column in the DataFrame.\n",
    "player_df['player'] = pop_list\n",
    "player_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all DataFrame column names but the last one.\n",
    "column_list = list(player_df.iloc[:, :-1])\n",
    "\n",
    "# Make player the second item in the list.\n",
    "column_list.insert(1, 'player')\n",
    "\n",
    "# Reassign the columns in the player_df DataFrame in this new order.\n",
    "player_df = player_df[column_list]\n",
    "\n",
    "# Verify that the columns are ordered the way you expect.\n",
    "player_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recheck the totals for NaN values by row.\n",
    "player_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise - Data manipulation part 2 - Impute missing values for columns\n",
    "\n",
    "# Plot the KDE for 'GP' over the probability-density histogram.\n",
    "plt.hist(player_df['GP'], density=True, bins=15)\n",
    "plt.title('GP histogram')\n",
    "sns.kdeplot(player_df['GP']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the KDE for 'MPG' over the probability-density histogram.\n",
    "plt.hist(player_df['MPG'], density=True, bins=15)\n",
    "plt.title('MPG histogram')\n",
    "sns.kdeplot(player_df['MPG']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the KDE for 'PER' over the probability-density histogram.\n",
    "plt.hist(player_df['PER'], density=True, bins=15)\n",
    "plt.title('PER histogram')\n",
    "sns.kdeplot(player_df['PER']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values in 'GP' and 'MPG' with the mean values of the respective columns.\n",
    "player_df[['GP','MPG']] = player_df[['GP','MPG']].fillna(value=player_df[['GP','MPG']].mean())\n",
    "\n",
    "# Recheck the totals for NaN values by row to ensure that the expected missing values are filled in.\n",
    "player_df.isna().sum()"
   ]
  },
  {
   "source": [
    "Cross-validate the R2 scores for the model\n",
    "Here you'll use a 10-fold cross validation. That is, Python will iterate through the data 10 times, reserving 10 percent of the data for testing and training on the other 90 percent of the data each time. You'll also plot a histogram of the results.\n",
    "\n",
    " Note\n",
    "\n",
    "As you read the Python code, keep in mind that you define the predictors as X by longstanding convention. For the purposes of building your model, you should use only rows that contain NaN values (player_df.dropna(how='any')). Then use the iloc DataFrame attribute to select columns by number rather than name (iloc[:, 4:-1]). Finally, use only the values from the resulting DataFrame slice rather than the slice in DataFrame form. (Here, the to_numpy() method is preferred over the DataFrame values attribute, per the pandas.DataFrame.values documentation)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the variables for the regression model as those rows that have no missing values.\n",
    "X = player_df.dropna(how='any').iloc[:, 5:-1].to_numpy()\n",
    "y = player_df.dropna(how='any').iloc[:, -1]\n",
    "\n",
    "# Define the regression model.\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Use the scikit-learn cross-validation function to fit this model 10 times and return the R2 scores.\n",
    "scores = cross_val_score(lin_reg, X, y, cv=10, scoring='r2')\n",
    "\n",
    "# Define the histogram of the scores and copy out information from the histogram.\n",
    "entries, bin_edges, patches = plt.hist(scores, bins=10);\n",
    "\n",
    "# Print out the mean and the results from the histogram.\n",
    "print('Mean r2 score: {:.4f}'.format(scores.mean()))\n",
    "for i in range(len(entries)):\n",
    "    if entries[i] > 0:\n",
    "        print('{:.0f}% of r2 scores are between {:.4f} and {:.4f}'.format(entries[i]*100/len(entries), \n",
    "        bin_edges[i], \n",
    "        bin_edges[i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the same regression model, this time using all of the available data.\n",
    "lin_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display a mask of rows in the DataFrame. Rows should contain at least one NaN value.\n",
    "mask = player_df.isnull().any(axis=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mask defined earlier to show the contents of specific columns of rows that contain NaN values.\n",
    "player_df.loc[mask].iloc[:, 5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values in 'PER' by using the regression model and mask.\n",
    "player_df.loc[mask, 'PER'] = lin_reg.predict(player_df.loc[mask].iloc[:, 5:-1])\n",
    "\n",
    "# Recheck the DataFrame for rows that have missing values.\n",
    "player_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the entire DataFrame.\n",
    "player_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df.to_csv('player_data_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n3\n4\n1\n"
     ]
    }
   ],
   "source": [
    "def digits(n):\n",
    "\tcount = 0\n",
    "\ttempnum = 0\n",
    "\tif n == 0:\n",
    "\t  return 1\n",
    "\t\n",
    "\twhile n != 0:\n",
    "\t\tcount += 1\n",
    "\t\tn =  n // 10\n",
    "\treturn count\n",
    "\t\n",
    "print(digits(25))   # Should print 2\n",
    "print(digits(144))  # Should print 3\n",
    "print(digits(1000)) # Should print 4\n",
    "print(digits(0))    # Should print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 \n0 \n"
     ]
    }
   ],
   "source": [
    "def multiplication_table(start, stop):\n",
    "\tfor x in range(start, stop):\n",
    "\t\tfor y in range(start):\n",
    "\t\t\tprint(str(x*y), end=\" \")\n",
    "\t\tprint()\n",
    "\n",
    "multiplication_table(1, 3)\n",
    "# Should print the multiplication table shown above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}